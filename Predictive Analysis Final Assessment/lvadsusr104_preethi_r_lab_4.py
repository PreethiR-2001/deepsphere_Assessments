# -*- coding: utf-8 -*-
"""LVADSUSR104_Preethi_R_Lab_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uVdGS_LNgpBjkxq_Z1sqcBxYossAFgEH
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, f1_score, recall_score, confusion_matrix, silhouette_score, davies_bouldin_score, calinski_harabasz_score, r2_score, mean_absolute_error
import time
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import IsolationForest

from sklearn.decomposition import PCA

df = pd.read_csv('/content/social_network.csv')
print(df.head())

print("Null values :", df.isnull().sum())
print("Any duplicates :", df.duplicated().sum())

print("Since it is anomaly detection, outliers should not be removed")

print("Data description :\n", df.describe())
print("\nData Information :\n", df.info)
print("\nData Shape :\n", df.shape)
print("\nData Columns :\n", df.columns)
print(df.head())
print(df.tail())

print(df.corr())

lb = LabelEncoder()
df['account_status'] = lb.fit_transform(df['account_status'])

x = df.drop(columns='account_creation_date')

ml=IsolationForest()
fit=ml.fit(x)
op=ml.predict(x)
print(op)
l=[]
for i in op:
  if i==-1:
    l.append('Anomaly')
  if i==1:
    l.append('Not Anomaly')
df['Result']=l

a=df[df['Result']=='Anomaly']
print(a)
n=df[df['Result']=='Not Anomaly']
print(n)

plt.scatter(a['login_activity'],a['suspicious_activity'],label='Anomaly',color='r')
plt.scatter(n['login_activity'],n['suspicious_activity'],label='Not Anomaly')
plt.xlabel('login_activity')
plt.ylabel('suspicious_activity')
plt.legend()
plt.title('Anomaly Detection')